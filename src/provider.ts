import OpenAI from "openai";

export interface StreamUpdate { type: 'reasoning' | 'content'; delta: string; }
export interface ApiMessage {
    role: 'user' | 'assistant' | 'system' | 'tool';
    content: string | null;
    reasoning_content?: string;
    tool_calls?: any[];
    tool_call_id?: string;
}

export interface AIProvider {
    generateContentStream(messages: ApiMessage[], onUpdate: (update: StreamUpdate) => void, tools?: any[]): Promise<ApiMessage>;
}

export class DeepSeekProvider implements AIProvider {
    private openai: OpenAI;
    constructor(apiKey: string) {
        this.openai = new OpenAI({ baseURL: 'https://api.deepseek.com', apiKey });
    }

    async generateContentStream(messages: ApiMessage[], onUpdate: (update: StreamUpdate) => void, tools?: any[]): Promise<ApiMessage> {
        try {
            const cleanedMessages = messages.map(m => {
                const msg: any = { role: m.role, content: m.content };
            
            // å¦‚æœè¿™æ¡æ¶ˆæ¯æœ‰å·¥å…·è°ƒç”¨ï¼Œå¿…é¡»æŠŠå®ƒçš„æ€è€ƒè¿‡ç¨‹å’Œå·¥å…·æŒ‡ä»¤ä¸€èµ·ä¼ å›å»ï¼
                if (m.tool_calls) {
                    msg.tool_calls = m.tool_calls;
                    msg.reasoning_content = m.reasoning_content; // ğŸ‘ˆ å…³é”®ï¼šä¿ç•™è¿™ä¸ª
                }
            
            // å¦‚æœæ˜¯å·¥å…·çš„ç»“æœæ¶ˆæ¯ï¼Œå¿…é¡»å¸¦ä¸Š ID
                if (m.tool_call_id) {
                    msg.tool_call_id = m.tool_call_id;
                }
            
                return msg;
            });

            const stream = await this.openai.chat.completions.create({
                model: "deepseek-reasoner",
                messages: cleanedMessages as any,
                stream: true,
                tools: tools && tools.length > 0 ? tools : undefined,
                tool_choice: "auto",
                max_tokens: 65000 // é˜²æ­¢æˆªæ–­
            });

            let fullContent = "", fullReasoning = "", toolCallsBuffer: any[] = [];

            for await (const chunk of stream) {
                const delta = chunk.choices[0]?.delta;
                if (!delta) continue;
                const reasoning = (delta as any).reasoning_content;
                if (reasoning) { fullReasoning += reasoning; onUpdate({ type: 'reasoning', delta: reasoning }); }
                if (delta.content) { fullContent += delta.content; onUpdate({ type: 'content', delta: delta.content }); }
                if (delta.tool_calls) {
                    for (const tc of delta.tool_calls) {
                        if (tc.index === undefined) continue;
                        if (!toolCallsBuffer[tc.index]) {
                            toolCallsBuffer[tc.index] = { id: tc.id, type: "function", function: { name: tc.function?.name, arguments: "" } };
                        }
                        if (tc.function?.arguments) toolCallsBuffer[tc.index].function.arguments += tc.function.arguments;
                    }
                }
            }
            return { role: 'assistant', content: fullContent || null, reasoning_content: fullReasoning, tool_calls: toolCallsBuffer.length > 0 ? toolCallsBuffer : undefined };
        } catch (error: any) {
            onUpdate({ type: 'content', delta: `[API Error]: ${error.message}` });
            return { role: 'assistant', content: error.message };
        }
    }
}

export class GeminiProvider implements AIProvider {
    private apiKey: string;
    constructor(apiKey: string) { this.apiKey = apiKey; }
    async generateContentStream(messages: ApiMessage[], onUpdate: (update: StreamUpdate) => void, tools?: any[]): Promise<ApiMessage> {
        const msg = "Gemini Provider æš‚æœªé€‚é… MCPã€‚";
        onUpdate({ type: 'content', delta: msg });
        return { role: 'assistant', content: msg };
    }
}